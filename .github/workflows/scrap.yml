name: GScrap

on:
  workflow_dispatch:  # Allows manual trigger
  schedule:
    - cron: "0 */2 * * *"  # This runs the job every 2 hours

jobs:
  scrape_emails:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository to access the code
      - name: Checkout repository
        uses: actions/checkout@v2

      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      # Step 3: Install dependencies directly without requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests gspread oauth2client

      # Step 4: Decode Google Sheets credentials
      - name: Decode Google Sheets credentials
        run: echo "${{ secrets.ENCODED_GOOGLE_SHEET_CREDENTIALS }}" | base64 --decode > credentials.json

      # Step 5: Run the email scraper script
      - name: Run email scraper script
        env:
          MY_GITHUB_API_KEYS: ${{ secrets.MY_GITHUB_API_KEYS }}  # Use MY_GITHUB_API_KEYS to match the script
        run: |
          python CloudScrap.py  # Make sure this matches your script filename
