name: GitHub Email Scraper

on:
  workflow_dispatch:  # Allows manual trigger
  schedule:
    - cron: "0 */6 * * *"  # This runs the job every 6 hours

jobs:
  scrape_emails:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository to access the code
      - name: Checkout repository
        uses: actions/checkout@v2

      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      # Step 3: Install dependencies directly without requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests gspread oauth2client

      # Step 4: Decode Google Sheets credentials
      - name: Decode Google Sheets credentials
        run: echo "${{ secrets.ENCODED_GOOGLE_SHEET_CREDENTIALS }}" | base64 --decode > credentials.json

      # Step 5: Run the email scraper script
      - name: Run email scraper script
        env:
          GITHUB_API_KEYS: ${{ secrets.GITHUB_API_KEYS }}  # GitHub API keys should be stored in GitHub Secrets
        run: |
          python your_script_name.py  # Replace with your script's filename
